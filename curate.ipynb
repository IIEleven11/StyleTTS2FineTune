{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_g_pzkJYGbM"
      },
      "source": [
        "# Dataset Analysis and Curation\n",
        "\n",
        "This is from from This guy's notebook [here](https://www.kaggle.com/code/maxbr0wn/fine-tuning-xtts-v2-english?scriptVersionId=173570803) and Coqui's TTS notebook [here](https://github.com/coqui-ai/TTS/blob/dev/notebooks/dataset_analysis/AnalyzeDataset.ipynb)\n",
        "\n",
        "# The only input you'll be required to give is the path to the dataset folder. Everything else should be automated. Including the curation/removal of poor quality samples.\n",
        "\n",
        "# Use this notebook with the provided known good dataset first. Then you can compare your own dataset.\n",
        "\n",
        "You will need to combine your train_list.txt and val_list.txt into a single \"metadata.csv\" file. The csv needs to be formatted without a header and in this order --> \n",
        "audio_file_name|transcription|transcription\n",
        "# Dont use the IPA translation.\n",
        "\n",
        "**Example:**\n",
        "audio_000001|It contained a bookcase: I soon possessed myself of a volume, taking care that it should be one stored with pictures.|It contained a bookcase: I soon possessed myself of a volume, taking care that it should be one stored with pictures.\n",
        "\n",
        "You can continue through each cell with the example dataset until it tells you to stop. Theres no need to do the cells beyond that point.\n",
        "\n",
        "When you are ready to use your own dataset youll have the option to remove the poor quality samples and regenerate the csv. At that point you can recreate the train_list and val_list.txt and phonemize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The cell below is to grab the reference good quality dataset. It can be skipped without any other modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading janeeyre, 1615805879 bytes compressed\n",
            "[==================================================] 1615805879 bytes downloaded\n",
            "Downloaded and uncompressed: janeeyre\n",
            "Dataset saved to: /home/eleven/dset/input/janeeyre\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'janeeyre:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4372173%2F7507317%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240608%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240608T194313Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D21443d92e1d8791f65ec5a33925c559685283f40417a61348248dc6fd8f18fd65f08c2ec964023417fa73c7ab98a3ed5a8f82384cef647c396805c1a8244545c879a5f38fe2724f09fe8a2a0046be8cdce398fca60e3aa2698fee1df45a19ee7834fd4beb4aa6d5db4a3bdc5637910b3deefcff20f682a57f4eaedc7d827b000fa15431ca593453f1da86dfe99b53d7ac8eeb8e4ac3b856b033147cabc3a09bccb994f8e02bbb15ef21970333a4e904b1b4db235fb5dbe8ecc09a5126e402b196ad6e8a06067950f34f40f6a804dfbd45434b01fed82ac79d8cb06ec8455e5d0946b00fcc396d7d4a19cb63c59ee9d079e46782628548cdc2aa69e10df1c9df1'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-04-22T15:36:30.444156Z",
          "iopub.status.busy": "2024-04-22T15:36:30.443821Z",
          "iopub.status.idle": "2024-04-22T15:37:18.910213Z",
          "shell.execute_reply": "2024-04-22T15:37:18.908144Z",
          "shell.execute_reply.started": "2024-04-22T15:36:30.444128Z"
        },
        "id": "u2c65P_1YGbN",
        "outputId": "1de6e023-c72a-4ea3-c45f-46c6eff680a1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/coqui-ai/TTS\n",
            "  Cloning https://github.com/coqui-ai/TTS to /tmp/pip-req-build-u_zzpk_7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/coqui-ai/TTS /tmp/pip-req-build-u_zzpk_7\n",
            "  Resolved https://github.com/coqui-ai/TTS to commit dbf1a08a0d4e47fdad6172e433eeb34bc6b13b4e\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting cython>=0.29.30 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for cython>=0.29.30 from https://files.pythonhosted.org/packages/45/82/077c13035d6f45d8b8b74d67e9f73f2bfc54ef8d1f79572790f6f7d2b4f5/Cython-3.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading Cython-3.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting scipy>=1.11.2 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for scipy>=1.11.2 from https://files.pythonhosted.org/packages/36/07/035d22ff9795129c5a847c64cb43c1fa9188826b59344fee28a3ab02e283/scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m892.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting torch>=2.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for torch>=2.1 from https://files.pythonhosted.org/packages/07/9a/4c5e74264439837814656201da13a898056a5201c976ef042544bceb840f/torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchaudio (from TTS==0.22.0)\n",
            "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/62/04/3acb3673dcc9f493e65798d752841137cfcc14220a8eb4ec8dc202382bcc/torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting soundfile>=0.12.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for soundfile>=0.12.0 from https://files.pythonhosted.org/packages/c1/07/7591f4efd29e65071c3a61b53725036ea8f73366a4920a481ebddaf8d0ca/soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
            "Collecting librosa>=0.10.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for librosa>=0.10.0 from https://files.pythonhosted.org/packages/8c/8a/2d231b35456506b7c98b3ab9bbf07917b205fed8615d2e59e976ab497fff/librosa-0.10.2.post1-py3-none-any.whl.metadata\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting scikit-learn>=1.3.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for scikit-learn>=1.3.0 from https://files.pythonhosted.org/packages/46/c0/63d3a8da39a2ee051df229111aa93f6dca2b56f8080abd34993938166455/scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting inflect>=5.6.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for inflect>=5.6.0 from https://files.pythonhosted.org/packages/94/f3/3e1a21ff247378f7bf03a7f065e714645240ac2dd55782fe9322bd6e76cb/inflect-7.2.1-py3-none-any.whl.metadata\n",
            "  Downloading inflect-7.2.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tqdm>=4.64.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for tqdm>=4.64.1 from https://files.pythonhosted.org/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyascii>=0.3.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for anyascii>=0.3.0 from https://files.pythonhosted.org/packages/4f/7b/a9a747e0632271d855da379532b05a62c58e979813814a57fa3b3afeb3a4/anyascii-0.3.2-py3-none-any.whl.metadata\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyyaml>=6.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for pyyaml>=6.0 from https://files.pythonhosted.org/packages/7b/5e/efd033ab7199a0b2044dab3b9f7a4f6670e6a52c089de572e928d2873b06/PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.6.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for fsspec>=2023.6.0 from https://files.pythonhosted.org/packages/8f/df/de2c06b316142063b6ccccc97cdc54185e3af771aa4f056d56f0db0e3466/fsspec-2024.6.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp>=3.8.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for aiohttp>=3.8.1 from https://files.pythonhosted.org/packages/24/99/e76e65ca811100b445d3c8af9764b27c5180ca11a15af694366424896647/aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from TTS==0.22.0) (24.0)\n",
            "Collecting mutagen==1.47.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for mutagen==1.47.0 from https://files.pythonhosted.org/packages/b0/7a/620f945b96be1f6ee357d211d5bf74ab1b7fe72a9f1525aafbfe3aee6875/mutagen-1.47.0-py3-none-any.whl.metadata\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting flask>=2.0.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for flask>=2.0.1 from https://files.pythonhosted.org/packages/61/80/ffe1da13ad9300f87c93af113edd0638c75138c42a0994becfacac078c06/flask-3.0.3-py3-none-any.whl.metadata\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pysbd>=0.3.4 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for pysbd>=0.3.4 from https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl.metadata\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for umap-learn>=0.5.1 from https://files.pythonhosted.org/packages/d1/1b/46802a050b1c55d10c4f59fc6afd2b45ac9b4f62b2e12092d3f599286f14/umap_learn-0.5.6-py3-none-any.whl.metadata\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for pandas<2.0,>=1.4 from https://files.pythonhosted.org/packages/56/73/3351beeb807dca69fcc3c4966bcccc51552bd01549a9b13c04ab00a43f21/pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting matplotlib>=3.7.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for matplotlib>=3.7.0 from https://files.pythonhosted.org/packages/41/f1/115e7c79b4506b4f0533acba742babd9718ff92eeca6d4205843173b6173/matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting trainer>=0.0.36 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for trainer>=0.0.36 from https://files.pythonhosted.org/packages/a0/38/c4381497fde987c72fc58d9b534dfd9e254e34d402e06be232f40e1baf66/trainer-0.0.36-py3-none-any.whl.metadata\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for coqpit>=0.0.16 from https://files.pythonhosted.org/packages/a3/d8/3f922be74a0aa9ef54ae1f82723fb1882988dce7fa420ba6af24e52c1987/coqpit-0.0.17-py3-none-any.whl.metadata\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jieba (from TTS==0.22.0)\n",
            "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pypinyin (from TTS==0.22.0)\n",
            "  Obtaining dependency information for pypinyin from https://files.pythonhosted.org/packages/67/bd/752e5d033a00dc33d0a955bf0bfd26a3c83a46b1404221e0f4a9ffbc7795/pypinyin-0.51.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading pypinyin-0.51.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from TTS==0.22.0)\n",
            "  Obtaining dependency information for hangul-romanize from https://files.pythonhosted.org/packages/e9/12/c5d2efd69d634d33c1a0a90256116bdefd023b27ca477f1fc5c7620aa21f/hangul_romanize-0.1.0-py3-none-any.whl.metadata\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS==0.22.0)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting jamo (from TTS==0.22.0)\n",
            "  Obtaining dependency information for jamo from https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl.metadata\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting nltk (from TTS==0.22.0)\n",
            "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting g2pkk>=0.1.1 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for g2pkk>=0.1.1 from https://files.pythonhosted.org/packages/25/9e/37665b4cf4e99dd4d294b178f79cd70fed2c5beff995e77132ceda97cfa1/g2pkk-0.1.2-py3-none-any.whl.metadata\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from TTS==0.22.0)\n",
            "  Obtaining dependency information for bangla from https://files.pythonhosted.org/packages/ea/2a/0dc2b2112f2cdac8694f1f782b4ea45a0693e453b76e21f224bad340591d/bangla-0.0.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from TTS==0.22.0)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting bnunicodenormalizer (from TTS==0.22.0)\n",
            "  Obtaining dependency information for bnunicodenormalizer from https://files.pythonhosted.org/packages/e9/37/df46a2375c462623ebf17258926cacb94e01a6159c93f9144a6b42bc33fe/bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting einops>=0.6.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for einops>=0.6.0 from https://files.pythonhosted.org/packages/44/5a/f0b9ad6c0a9017e62d4735daaeb11ba3b6c009d69a26141b258cd37b5588/einops-0.8.0-py3-none-any.whl.metadata\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers>=4.33.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for transformers>=4.33.0 from https://files.pythonhosted.org/packages/d9/b7/98f821d70102e2d38483bbb7013a689d2d646daa4495377bc910374ad727/transformers-4.41.2-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec>=0.1.1 (from TTS==0.22.0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting unidecode>=1.3.2 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for unidecode>=1.3.2 from https://files.pythonhosted.org/packages/84/b7/6ec57841fb67c98f52fc8e4a2d96df60059637cba077edc569a302a8ffc7/Unidecode-1.3.8-py3-none-any.whl.metadata\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from TTS==0.22.0)\n",
            "  Obtaining dependency information for num2words from https://files.pythonhosted.org/packages/8f/f0/ca1228af2bcbce2fdf2b23d58643c84253b88a3c1cd9dba391ca683c4b21/num2words-0.5.13-py3-none-any.whl.metadata\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting spacy[ja]>=3 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for spacy[ja]>=3 from https://files.pythonhosted.org/packages/e0/ce/b5e6b02165881547ad251b0b172ebf496b9181a95833f94012af82d044df/spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting numpy>=1.24.3 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for numpy>=1.24.3 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting numba>=0.57.0 (from TTS==0.22.0)\n",
            "  Obtaining dependency information for numba>=0.57.0 from https://files.pythonhosted.org/packages/54/f2/7d1579037643c874fa73516ea84c07e8d30ea347fb1a88c03b198447655d/numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting Babel<3.0.0,>=2.8.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for Babel<3.0.0,>=2.8.0 from https://files.pythonhosted.org/packages/27/45/377f7e32a5c93d94cd56542349b34efab5ca3f9e2fd5a68c5e93169aa32d/Babel-2.15.0-py3-none-any.whl.metadata\n",
            "  Downloading Babel-2.15.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for dateparser~=1.1.0 from https://files.pythonhosted.org/packages/7a/bf/457ed5be028fb235f8f5ad40b5ddbf67023e0017090ea324d0fe6239a73c/dateparser-1.1.8-py2.py3-none-any.whl.metadata\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gruut-lang-en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for jsonlines~=1.2.0 from https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for networkx<3.0.0,>=2.5.0 from https://files.pythonhosted.org/packages/42/31/d2f89f1ae42718f8c8a9e440ebe38d7d5fe1e0d9eb9178ce779e365b3ab0/networkx-2.8.8-py3-none-any.whl.metadata\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for python-crfsuite~=0.9.7 from https://files.pythonhosted.org/packages/f0/94/9b35b4cd490c0fa52df409d80585636728217eaae38707941ea255d3f9db/python_crfsuite-0.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading python_crfsuite-0.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting gruut-lang-de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gruut-lang-es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gruut-lang-fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp>=3.8.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp>=3.8.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp>=3.8.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b3/c9/0bc5ee7e1f5cc7358ab67da0b7dfe60fbd05c254cea5c6108e7d1ae28c63/frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.8.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/52/ec/be54a3ad110f386d5bd7a9a42a4ff36b3cd723ebe597f41073a73ffa16b8/multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.8.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/9f/ea/94ad7d8299df89844e666e4aa8a0e9b88e02416cd6a7dd97969e9eae5212/yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting Werkzeug>=3.0.0 (from flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for Werkzeug>=3.0.0 from https://files.pythonhosted.org/packages/9d/6e/e792999e816d19d7fcbfa94c730936750036d65656a76a5a688b57a656c4/werkzeug-3.0.3-py3-none-any.whl.metadata\n",
            "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Jinja2>=3.1.2 (from flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for Jinja2>=3.1.2 from https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl.metadata\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting itsdangerous>=2.1.2 (from flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for itsdangerous>=2.1.2 from https://files.pythonhosted.org/packages/04/96/92447566d16df59b2a776c0fb82dbc4d9e07cd95062562af01e408583fc4/itsdangerous-2.2.0-py3-none-any.whl.metadata\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting click>=8.1.3 (from flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for click>=8.1.3 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting blinker>=1.6.2 (from flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl.metadata\n",
            "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting more-itertools (from inflect>=5.6.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/50/e2/8e10e465ee3987bb7c9ab69efb91d867d93959095f4807db102d07995d94/more_itertools-10.2.0-py3-none-any.whl.metadata\n",
            "  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=5.6.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for typeguard>=4.0.1 from https://files.pythonhosted.org/packages/eb/de/be0ba39ee73760bf33329b7c6f95bc67e96593c69c881671e312538e24bb/typeguard-4.3.0-py3-none-any.whl.metadata\n",
            "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: typing-extensions in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from inflect>=5.6.0->TTS==0.22.0) (4.12.2)\n",
            "Collecting audioread>=2.1.9 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting joblib>=0.14 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for joblib>=0.14 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from librosa>=0.10.0->TTS==0.22.0) (5.1.1)\n",
            "Collecting pooch>=1.1 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for pooch>=1.1 from https://files.pythonhosted.org/packages/a8/87/77cc11c7a9ea9fd05503def69e3d18605852cd0d4b0d3b8f15bbeb3ef1d1/pooch-1.8.2-py3-none-any.whl.metadata\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/2b/97/cbce72f9c8b5c9c667eb55dc55be20a87c610dba55c0466c77498c1a8c97/soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting lazy-loader>=0.1 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for lazy-loader>=0.1 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa>=0.10.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for msgpack>=1.0 from https://files.pythonhosted.org/packages/f6/f0/a7bdb48223cd21b9abed814b08fca8fe6a40931e70ec97c24d2f15d68ef3/msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/ee/c0/9bd123d676eb61750e116a2cd915b06483fc406143cfc36c7f263f0f5368/contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/0a/79/b5be063ea65d048a041ad8438fa1e8c7c4bf9dc3f4ac2794a850fe70c5c5/fonttools-4.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading fonttools-4.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/17/ba/17a706b232308e65f57deeccae503c268292e6a091313f6ce833a23093ea/kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/81/ff/ad3c942d865f9e45ce84eeb31795e6d4d94e1f1eea51026d5154028510d7/pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl.metadata\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS==0.22.0) (2.9.0.post0)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS==0.22.0)\n",
            "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.57.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for llvmlite<0.43,>=0.42.0dev0 from https://files.pythonhosted.org/packages/a4/1f/300788b5eab99aec872ed2f3647386d7d7f7bbf4f99c91e9e023b404ff7f/llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.0,>=1.4->TTS==0.22.0)\n",
            "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for cffi>=1.0 from https://files.pythonhosted.org/packages/9b/89/a31c81e36bbb793581d8bba4406a8aac4ba84b2559301c44eef81f4cf5df/cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/93/1b/d880be7ac028cab6bf980acf005c16c0ff381f0c0ba1fd60c284626df3fd/murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/e5/bc/761acaf88b1fa69a6b75b55c24fbd8b47dab1a3c414d9512e907a646a048/cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/db/69/d9ab108dc670b5be9e292bbd555f39e6eb0a4baab25cd28f792850d5e65b/preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for thinc<8.3.0,>=8.2.2 from https://files.pythonhosted.org/packages/06/06/cb247012a34e7043f911e9bcb0bdf0b5daa37cd1130e51afaa48a61ff5a6/thinc-8.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading thinc-8.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/e2/a0/153375ade1ca9d33543da7d512329ea9a7d40dc0e0832599f4228b9d761b/srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl.metadata\n",
            "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting requests<3.0.0,>=2.13.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for requests<3.0.0,>=2.13.0 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/e6/f5/80931903275942770f1112b524f1948f6d6ebd44725425025ca838800de2/pydantic-2.7.3-py3-none-any.whl.metadata\n",
            "  Downloading pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from spacy[ja]>=3->TTS==0.22.0) (65.5.0)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/58/70/4058ab0ebb082b18d06888e711baed7f33354a5e0b363bb627586d8c323a/langcodes-3.4.0-py3-none-any.whl.metadata\n",
            "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for sudachipy!=0.6.1,>=0.5.2 from https://files.pythonhosted.org/packages/b9/14/2f21de25cf6aad359c35ab1899098c2cbc804f0d473beeff423b46e2e74d/SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for sudachidict-core>=20211220 from https://files.pythonhosted.org/packages/57/8a/b15e9c7a2b601eea484af8e2d958d22b62315476e954794c3a186615edd1/SudachiDict_core-20240409-py3-none-any.whl.metadata\n",
            "  Downloading SudachiDict_core-20240409-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting filelock (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/41/24/0b023b6537dfc9bae2c779353998e3e99ac7dfff4222fc6126650e93c3f3/filelock-3.14.0-py3-none-any.whl.metadata\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sympy (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/61/53/e18c8c97d0b2724d85c9830477e3ebea3acf1dcdc6deb344d5d9c93a9946/sympy-1.12.1-py3-none-any.whl.metadata\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.1.105 from https://files.pythonhosted.org/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.1.105 from https://files.pythonhosted.org/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.1.105 from https://files.pythonhosted.org/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cublas-cu12==12.1.3.1 from https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cufft-cu12==11.0.2.54 from https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-curand-cu12==10.3.2.106 from https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cusolver-cu12==11.4.5.107 from https://files.pythonhosted.org/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-cusparse-cu12==12.1.0.106 from https://files.pythonhosted.org/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-nccl-cu12==2.20.5 from https://files.pythonhosted.org/packages/4b/2a/0a131f572aa09f741c30ccd45a8e56316e8be8dfc7bc19bf0ab7cfef7b19/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-nvtx-cu12==12.1.105 from https://files.pythonhosted.org/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for triton==2.3.1 from https://files.pythonhosted.org/packages/64/16/956b7b9d2ed3a437a1a06792b2ae2e3c49147296ba2f4d59fcee376ded8f/triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/16/03/7e96a2ccbb752857f50c0c1355b1c52d5922be43fe0691847e520750e5c7/nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: psutil in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from trainer>=0.0.36->TTS==0.22.0) (5.9.8)\n",
            "Collecting tensorboard (from trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/0a/32/2e8545fb0592f33e3aca5951e8b01008b76d61b440658cbdc37b4eaebf0b/tensorboard-2.17.0-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers>=4.33.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for huggingface-hub<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/66/e8/bbbad5c7b49c68def42830f96c606e693bfa935a886740a363f04cb84e44/huggingface_hub-0.23.3-py3-none-any.whl.metadata\n",
            "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.33.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/39/29/8158a6e69e97b9c72fab0b46fe4d57c789d07ef91fe4afde23721e7cac61/regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers>=4.33.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/a7/03/fb50fc03f86016b227a967c8d474f90230c885c0d18f78acdfda7a96ce56/tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers>=4.33.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/d5/85/1e7d2804cbf82204cde462d16f1cb0ff5814b03f559fb46ceaa6b7020db4/safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/bf/06/18c0e17eb245b7caeb861f2ff747adb0575500183b6ec4282d5350d29e9f/pynndescent-0.5.12-py3-none-any.whl.metadata\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.0->TTS==0.22.0)\n",
            "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting tzlocal (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Obtaining dependency information for tzlocal from https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl.metadata\n",
            "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask>=2.0.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/97/18/c30da5e7a0e7f4603abfc6780574131221d9148f323752c2755d48abad30/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: six in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (1.16.0)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/12/5f/139464da89c49afcc8bb97ebad48818a535220ce01b1f24c61fb80dbe4d0/language_data-1.2.0-py3-none-any.whl.metadata\n",
            "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.10.0->TTS==0.22.0) (4.2.2)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.18.4 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for pydantic-core==2.18.4 from https://files.pythonhosted.org/packages/d6/4b/51141c5ea1874e7204efac93899eefcb690ff6772a92c9a6521b32e5b71f/pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/40/26/f35951c45070edc957ba40a5b1db3cf60a9dbb1b350c2d5bef03e01e61de/charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for idna<4,>=2.5 from https://files.pythonhosted.org/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl.metadata\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/5b/11/1e78951465b4a225519b8c3ad29769c49e0d8d157a070f681d5b6d64737f/certifi-2024.6.2-py3-none-any.whl.metadata\n",
            "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/dc/23/eb01450dc284a7ea8ebc0e5296f1f8fdbe5299169f4c318f836b4284a119/blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
            "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/bc/ba/d8f2c0151585519759135550574385dd7a223abbc6b6c06dab7ada565773/cloudpathlib-0.18.1-py3-none-any.whl.metadata\n",
            "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for smart-open<8.0.0,>=5.2.1 from https://files.pythonhosted.org/packages/65/12/cc24847b4b0b124501a33cd8f7963f79f6f6584bc7f2f4fc16bbbaa54c8f/smart_open-7.0.4-py3-none-any.whl.metadata\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=2.1->TTS==0.22.0)\n",
            "  Obtaining dependency information for mpmath<1.4.0,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/11/4b/a6e4922029d8bd89e637c62f90a50a85add9ebdc5be65154956a7c2b82a1/grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/fc/b3/0c0c994fe49cd661084f8d5dc06562af53818cc0abefaca35bdc894577c3/Markdown-3.6-py3-none-any.whl.metadata\n",
            "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard->trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for protobuf!=4.24.0,<5.0.0,>=3.19.6 from https://files.pythonhosted.org/packages/15/db/7f731524fe0e56c6b2eb57d05b55d3badd80ef7d1f1ed59db191b2fdd8ab/protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->trainer>=0.0.36->TTS==0.22.0)\n",
            "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for marisa-trie>=0.7.7 from https://files.pythonhosted.org/packages/09/a8/2a08ba5cc9040d478ea727abe95b00926c34f792065de95fb2db5fe922e8/marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/eleven/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS==0.22.0) (2.18.0)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/6e/52/2da48b35193e39ac53cfb141467d9f259851522d0e8c87153f0ba4205fb1/wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[ja]>=3->TTS==0.22.0)\n",
            "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "Using cached coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading Cython-3.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Using cached inflect-7.2.1-py3-none-any.whl (34 kB)\n",
            "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "Using cached trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "Using cached Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "Using cached bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Using cached hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Downloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Using cached Babel-2.15.0-py3-none-any.whl (9.6 MB)\n",
            "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
            "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (464 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.8/464.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "Downloading fonttools-4.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Using cached networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "Downloading python_crfsuite-0.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.9/490.9 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n",
            "Downloading SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.1/920.1 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
            "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
            "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Using cached more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached idna-3.7-py3-none-any.whl (66 kB)\n",
            "Using cached language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
            "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
            "Downloading marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: TTS, encodec, bnnumerizer, jieba, gruut-ipa, gruut-lang-de, gruut-lang-en, gruut-lang-es, gruut-lang-fr, gruut\n",
            "  Building wheel for TTS (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for TTS: filename=TTS-0.22.0-cp311-cp311-linux_x86_64.whl size=903515 sha256=d2146d45a57b9ca48e44ee681bf2212c1925a64f1192b02d597738633ad13c29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wcca7t76/wheels/f4/ec/f1/ee66197160dfd90159f33c4434e521e1ce613475750baa8ee7\n",
            "  Building wheel for encodec (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=7047026018ce58f4a31160a0a848b466dc095ca6cd72e214af4a06e0bf0e9c18\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for bnnumerizer (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=550a6932e0f41704d8f5d64a0766a243d914da5b0196b936930a08bd77e7b70a\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\n",
            "  Building wheel for jieba (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=9386f9db150f7f607dc9fc4758d60472c5b83860a39ceca766366ce440da8e6a\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/ac/60/cf/538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
            "  Building wheel for gruut-ipa (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=8f7407254994f0f44bd12872c3947051ac86ebd4e37464e8122235a893c32d64\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\n",
            "  Building wheel for gruut-lang-de (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut-lang-de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498180 sha256=df2170da2a4544a87a7225aaa9cf5e25037d8c4e46ea3894612cde725b192820\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/c4/ad/f3/eecf61483881d7a8a83ece48eeaf9ee3ad202ccb530863d9e5\n",
            "  Building wheel for gruut-lang-en (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut-lang-en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297180 sha256=6865be7f533167b7503c8e3be07b9224540ea841aa759664b1a7d5723071c753\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/e2/78/bd/1d87e79fe8b770d31295d9340cc05bc16ddb892d0bae94a58b\n",
            "  Building wheel for gruut-lang-es (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut-lang-es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173798 sha256=8873135b3c7906dcaabf72d335bd5feb648437062f21f50f513322af4b5c61d0\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/7e/80/02/78d177dbdf2925c013cb935a430e98930b399e817c83586bbc\n",
            "  Building wheel for gruut-lang-fr (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut-lang-fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968768 sha256=9344d7c7e31b56723c511060f1820043442a3e4f24ed41c0834a74721a55838f\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\n",
            "  Building wheel for gruut (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75791 sha256=d441a8fbb21bb1a63ef72131067f3c8390af9a28b888e9f88770a8fc0dcfabab\n",
            "  Stored in directory: /home/eleven/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\n",
            "Successfully built TTS encodec bnnumerizer jieba gruut-ipa gruut-lang-de gruut-lang-en gruut-lang-es gruut-lang-fr gruut\n",
            "Installing collected packages: sudachipy, pytz, python-crfsuite, mpmath, jieba, jamo, hangul-romanize, gruut-lang-fr, gruut-lang-es, gruut-lang-en, gruut-lang-de, docopt, cymem, bnunicodenormalizer, bnnumerizer, bangla, wrapt, wasabi, urllib3, unidecode, tzlocal, typeguard, tqdm, threadpoolctl, tensorboard-data-server, sympy, sudachidict-core, spacy-loggers, spacy-legacy, shellingham, safetensors, regex, pyyaml, pysbd, pypinyin, pyparsing, pydantic-core, pycparser, protobuf, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, num2words, networkx, mutagen, murmurhash, multidict, msgpack, more-itertools, mdurl, MarkupSafe, markdown, marisa-trie, llvmlite, lazy-loader, kiwisolver, jsonlines, joblib, itsdangerous, idna, gruut-ipa, grpcio, fsspec, frozenlist, fonttools, filelock, einops, cython, cycler, coqpit, cloudpathlib, click, charset-normalizer, certifi, catalogue, blinker, Babel, audioread, attrs, anyascii, annotated-types, absl-py, yarl, Werkzeug, triton, srsly, soxr, smart-open, scipy, requests, pydantic, preshed, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nltk, markdown-it-py, language-data, Jinja2, inflect, dateparser, contourpy, cffi, blis, aiosignal, tensorboard, soundfile, scikit-learn, rich, pooch, nvidia-cusolver-cu12, matplotlib, langcodes, huggingface-hub, gruut, g2pkk, flask, confection, aiohttp, typer, torch, tokenizers, thinc, pynndescent, librosa, weasel, umap-learn, transformers, trainer, torchaudio, spacy, encodec, TTS\n",
            "Successfully installed Babel-2.15.0 Jinja2-3.1.4 MarkupSafe-2.1.5 TTS-0.22.0 Werkzeug-3.0.3 absl-py-2.1.0 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 anyascii-0.3.2 attrs-23.2.0 audioread-3.0.1 bangla-0.0.2 blinker-1.8.2 blis-0.7.11 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 catalogue-2.0.10 certifi-2024.6.2 cffi-1.16.0 charset-normalizer-3.3.2 click-8.1.7 cloudpathlib-0.18.1 confection-0.1.5 contourpy-1.2.1 coqpit-0.0.17 cycler-0.12.1 cymem-2.0.8 cython-3.0.10 dateparser-1.1.8 docopt-0.6.2 einops-0.8.0 encodec-0.1.1 filelock-3.14.0 flask-3.0.3 fonttools-4.53.0 frozenlist-1.4.1 fsspec-2024.6.0 g2pkk-0.1.2 grpcio-1.64.1 gruut-2.2.3 gruut-ipa-0.13.0 gruut-lang-de-2.0.0 gruut-lang-en-2.0.0 gruut-lang-es-2.0.0 gruut-lang-fr-2.0.2 hangul-romanize-0.1.0 huggingface-hub-0.23.3 idna-3.7 inflect-7.2.1 itsdangerous-2.2.0 jamo-0.4.1 jieba-0.42.1 joblib-1.4.2 jsonlines-1.2.0 kiwisolver-1.4.5 langcodes-3.4.0 language-data-1.2.0 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.42.0 marisa-trie-1.2.0 markdown-3.6 markdown-it-py-3.0.0 matplotlib-3.9.0 mdurl-0.1.2 more-itertools-10.2.0 mpmath-1.3.0 msgpack-1.0.8 multidict-6.0.5 murmurhash-1.0.10 mutagen-1.47.0 networkx-2.8.8 nltk-3.8.1 num2words-0.5.13 numba-0.59.1 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 pillow-10.3.0 pooch-1.8.2 preshed-3.0.9 protobuf-4.25.3 pycparser-2.22 pydantic-2.7.3 pydantic-core-2.18.4 pynndescent-0.5.12 pyparsing-3.1.2 pypinyin-0.51.0 pysbd-0.3.4 python-crfsuite-0.9.10 pytz-2024.1 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 rich-13.7.1 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.13.1 shellingham-1.5.4 smart-open-7.0.4 soundfile-0.12.1 soxr-0.3.7 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 sudachidict-core-20240409 sudachipy-0.6.8 sympy-1.12.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 thinc-8.2.4 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 torchaudio-2.3.1 tqdm-4.66.4 trainer-0.0.36 transformers-4.41.2 triton-2.3.1 typeguard-4.3.0 typer-0.12.3 tzlocal-5.2 umap-learn-0.5.6 unidecode-1.3.8 urllib3-2.2.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.16.0 yarl-1.9.4\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/coqui-ai/TTS\n",
        "\n",
        "# or !pip install git+https://github.com/coqui-ai/TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:18.913394Z",
          "iopub.status.busy": "2024-04-22T15:37:18.912934Z",
          "iopub.status.idle": "2024-04-22T15:37:18.931371Z",
          "shell.execute_reply": "2024-04-22T15:37:18.929889Z",
          "shell.execute_reply.started": "2024-04-22T15:37:18.913352Z"
        },
        "id": "O1E49ChbYGbN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import shutil\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from multiprocessing import Pool\n",
        "from matplotlib import pylab as plt\n",
        "from collections import Counter\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.datasets.formatters import *\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset\n",
        "\n",
        "Input path to the folder that contains the metadata.csv the wavs folder.\n",
        "/path/to/your/dataset/\n",
        "├── metadata.csv\n",
        "└── wavs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:18.937201Z",
          "iopub.status.busy": "2024-04-22T15:37:18.935372Z",
          "iopub.status.idle": "2024-04-22T15:37:18.960885Z",
          "shell.execute_reply": "2024-04-22T15:37:18.959394Z",
          "shell.execute_reply.started": "2024-04-22T15:37:18.937142Z"
        },
        "id": "dTCvk-NYYGbO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "training_dir = '/kaggle/input/trmp'\n",
        "NUM_PROC = 4\n",
        "DATASET_CONFIG = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=training_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:18.963526Z",
          "iopub.status.busy": "2024-04-22T15:37:18.963043Z",
          "iopub.status.idle": "2024-04-22T15:37:18.974426Z",
          "shell.execute_reply": "2024-04-22T15:37:18.972983Z",
          "shell.execute_reply.started": "2024-04-22T15:37:18.963481Z"
        },
        "id": "k97mvHiGYGbO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    with open(meta_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            print(f\"Processing line: {line.strip()}\")  # Debugging statement\n",
        "            cols = line.split(\"|\")\n",
        "            print(f\"Columns: {cols}\")  # Debugging statement\n",
        "            if len(cols) < 2:\n",
        "                print(f\"Skipping line due to insufficient columns: {line.strip()}\")\n",
        "                continue\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0] + \".wav\")\n",
        "            text = cols[1]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:18.976313Z",
          "iopub.status.busy": "2024-04-22T15:37:18.975958Z",
          "iopub.status.idle": "2024-04-22T15:37:19.301762Z",
          "shell.execute_reply": "2024-04-22T15:37:19.3003Z",
          "shell.execute_reply.started": "2024-04-22T15:37:18.976286Z"
        },
        "id": "1kJ4K1oQYGbO",
        "outputId": "1ae12d3d-4e9d-4df1-a3d8-59eddbe728ed",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'metadata.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_samples, eval_samples \u001b[38;5;241m=\u001b[39m \u001b[43mload_tts_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_CONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     items \u001b[38;5;241m=\u001b[39m train_samples \u001b[38;5;241m+\u001b[39m eval_samples\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/TTS/tts/datasets/__init__.py:120\u001b[0m, in \u001b[0;36mload_tts_samples\u001b[0;34m(datasets, eval_split, formatter, eval_split_max_size, eval_split_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _get_formatter_by_name(formatter_name)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# load train set\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_file_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignored_speakers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignored_speakers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(meta_data_train) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] No training samples found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_file_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m add_extra_keys(meta_data_train, language, dataset_name)\n",
            "Cell \u001b[0;32mIn[32], line 4\u001b[0m, in \u001b[0;36mformatter\u001b[0;34m(root_path, meta_file, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m txt_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, meta_file)\n\u001b[1;32m      3\u001b[0m items \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmeta_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing line: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging statement\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'metadata.csv'"
          ]
        }
      ],
      "source": [
        "train_samples, eval_samples = load_tts_samples(DATASET_CONFIG, eval_split=True, formatter=formatter)\n",
        "if eval_samples is not None:\n",
        "    items = train_samples + eval_samples\n",
        "else:\n",
        "    items = train_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:19.304106Z",
          "iopub.status.busy": "2024-04-22T15:37:19.303607Z",
          "iopub.status.idle": "2024-04-22T15:37:19.311365Z",
          "shell.execute_reply": "2024-04-22T15:37:19.309772Z",
          "shell.execute_reply.started": "2024-04-22T15:37:19.304073Z"
        },
        "id": "Wy77kazaYGbO",
        "outputId": "9d51b629-2bde-468a-e48b-3efe9eea08ee",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# How many audio files are there in the dataset?\n",
        "print(\" > Number of audio files: {}\".format(len(items)))\n",
        "print(items[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:19.324514Z",
          "iopub.status.busy": "2024-04-22T15:37:19.324058Z",
          "iopub.status.idle": "2024-04-22T15:37:24.787905Z",
          "shell.execute_reply": "2024-04-22T15:37:24.786631Z",
          "shell.execute_reply.started": "2024-04-22T15:37:19.324464Z"
        },
        "id": "m0XmgIeOYGbO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# print out names of missing wavs\n",
        "wav_files = []\n",
        "for item in items:\n",
        "    wav_file = item[\"audio_file\"].strip()\n",
        "    wav_files.append(wav_file)\n",
        "    if not os.path.exists(wav_file):\n",
        "        print(wav_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:24.790477Z",
          "iopub.status.busy": "2024-04-22T15:37:24.789884Z",
          "iopub.status.idle": "2024-04-22T15:37:24.80202Z",
          "shell.execute_reply": "2024-04-22T15:37:24.800905Z",
          "shell.execute_reply.started": "2024-04-22T15:37:24.790432Z"
        },
        "id": "QfgY6hn5YGbP",
        "outputId": "dd7751e7-1c92-4c5c-9992-7ee31b6f96ec",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# print out names of duplicate wavs\n",
        "c = Counter(wav_files)\n",
        "print([item for item, count in c.items() if count > 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAP44a_dYGbP"
      },
      "source": [
        "### Compute Audio/Text Lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:24.804338Z",
          "iopub.status.busy": "2024-04-22T15:37:24.80358Z",
          "iopub.status.idle": "2024-04-22T15:37:58.131623Z",
          "shell.execute_reply": "2024-04-22T15:37:58.127975Z",
          "shell.execute_reply.started": "2024-04-22T15:37:24.804303Z"
        },
        "id": "Vks2xUkxYGbP",
        "outputId": "31ca89d4-c682-49b0-c9f3-e86a155c7e48",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_item(item):\n",
        "    text = item[\"text\"].strip()\n",
        "    file_name = item[\"audio_file\"].strip()\n",
        "    audio, sr = librosa.load(file_name, sr=None)\n",
        "    audio_len = len(audio) / sr\n",
        "    text_len = len(text)\n",
        "    return file_name, text, text_len, audio, audio_len\n",
        "\n",
        "# This will take a while depending on size of dataset\n",
        "if NUM_PROC == 1:\n",
        "    data = []\n",
        "    for m in tqdm(items):\n",
        "        data += [load_item(m)]\n",
        "else:\n",
        "    with Pool(NUM_PROC) as p:\n",
        "        data = list(tqdm(p.imap(load_item, items), total=len(items)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.135357Z",
          "iopub.status.busy": "2024-04-22T15:37:58.134679Z",
          "iopub.status.idle": "2024-04-22T15:37:58.282561Z",
          "shell.execute_reply": "2024-04-22T15:37:58.281198Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.135312Z"
        },
        "id": "DQPFqNRTYGbP",
        "outputId": "b1d2765d-3b8a-41b9-b4c0-d1c2cec816ec",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# look at breadth of vocabulary\n",
        "w_count = Counter()\n",
        "for item in tqdm(data):\n",
        "    text = item[1].lower().strip()\n",
        "    for word in text.split():\n",
        "        w_count[word] += 1\n",
        "print(\" > Number of words: {}\".format(len(w_count)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.284674Z",
          "iopub.status.busy": "2024-04-22T15:37:58.284311Z",
          "iopub.status.idle": "2024-04-22T15:37:58.329275Z",
          "shell.execute_reply": "2024-04-22T15:37:58.327893Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.284645Z"
        },
        "id": "5CJ8pN4pYGbP",
        "outputId": "de42c139-6968-4c44-ccb2-8f806e2b4a3b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#length of text, duration of audio in seconds and compare\n",
        "text_vs_durs = {}  # text length vs audio duration\n",
        "text_len_counter = Counter()  # number of sentences with the keyed length\n",
        "lengths = []\n",
        "for item in tqdm(data):\n",
        "    text = item[1].lower().strip()\n",
        "    text_len = len(text)\n",
        "    text_len_counter[text_len] += 1\n",
        "    lengths.append(text_len)\n",
        "    audio_len = item[-1]\n",
        "    try:\n",
        "        text_vs_durs[text_len] += [audio_len]\n",
        "    except:\n",
        "        text_vs_durs[text_len] = [audio_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.331174Z",
          "iopub.status.busy": "2024-04-22T15:37:58.330832Z",
          "iopub.status.idle": "2024-04-22T15:37:58.363503Z",
          "shell.execute_reply": "2024-04-22T15:37:58.362238Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.331145Z"
        },
        "id": "1B9PthnlYGbP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#for each bucket of char lengths, find averages for that length vs duration of audio\n",
        "text_vs_avg = {}\n",
        "text_vs_median = {}\n",
        "text_vs_std = {}\n",
        "for key, durs in text_vs_durs.items():\n",
        "    text_vs_avg[key] = np.mean(durs)\n",
        "    text_vs_median[key] = np.median(durs)\n",
        "    text_vs_std[key] = np.std(durs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.365279Z",
          "iopub.status.busy": "2024-04-22T15:37:58.364923Z",
          "iopub.status.idle": "2024-04-22T15:37:58.383115Z",
          "shell.execute_reply": "2024-04-22T15:37:58.381752Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.36525Z"
        },
        "id": "XUp26YNMYGbP",
        "outputId": "f55d7919-3eb6-45b9-893b-fd44ae3a3724",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#per char duration\n",
        "sec_per_chars = []\n",
        "for item in data:\n",
        "    text = item[1]\n",
        "    dur = item[-1]\n",
        "    sec_per_char = dur / len(text)\n",
        "    sec_per_chars.append(sec_per_char)\n",
        "\n",
        "mean = np.mean(sec_per_chars)\n",
        "std = np.std(sec_per_chars)\n",
        "print(mean)\n",
        "print(std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu1Z3hs5YGbP"
      },
      "source": [
        "### Visualise Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.385434Z",
          "iopub.status.busy": "2024-04-22T15:37:58.384956Z",
          "iopub.status.idle": "2024-04-22T15:37:58.756753Z",
          "shell.execute_reply": "2024-04-22T15:37:58.755502Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.385374Z"
        },
        "id": "Kw8jR0AnYGbP",
        "outputId": "3bbb51b4-8afd-49c3-ae1d-b4dda2d8b297",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.title(\"text length vs mean audio duration\")\n",
        "plt.scatter(list(text_vs_avg.keys()), list(text_vs_avg.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQBKdXRGYGbP"
      },
      "source": [
        "Note that \"text length\" is amount of chars. Audio duration should basically be a linear function of text length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:58.759577Z",
          "iopub.status.busy": "2024-04-22T15:37:58.758513Z",
          "iopub.status.idle": "2024-04-22T15:37:59.144729Z",
          "shell.execute_reply": "2024-04-22T15:37:59.143465Z",
          "shell.execute_reply.started": "2024-04-22T15:37:58.759543Z"
        },
        "id": "CyI4yi5MYGbP",
        "outputId": "f74cf873-c6b3-453e-c6a3-4908be67b0a4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.title(\"text length vs STD\")\n",
        "plt.scatter(list(text_vs_std.keys()), list(text_vs_std.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Z7WnTxYGbQ"
      },
      "source": [
        "This is showing us, for each set of data items with a particular char length, what is one standard deviation in audio duration for that set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:59.146775Z",
          "iopub.status.busy": "2024-04-22T15:37:59.146307Z",
          "iopub.status.idle": "2024-04-22T15:37:59.536863Z",
          "shell.execute_reply": "2024-04-22T15:37:59.535491Z",
          "shell.execute_reply.started": "2024-04-22T15:37:59.146742Z"
        },
        "id": "unY18k-OYGbQ",
        "outputId": "b668478e-8b9e-42b5-e6fa-fd9c219eca7f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.hist(lengths, bins=20, edgecolor='black')  # Adjust the number of bins as needed\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Text Lengths in TTS Dataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFk3y6JgYGbQ"
      },
      "source": [
        "The TTS docs recommends a 'Gaussian-like' distribution of clip lengths. A fairly uniform distribution should be fine too. I think the most important thing is to have examples across a range of different lengths. From my experience, the model does not generalise well across different sequence lengths (i.e., if you fine-tune with no short 1.5s clips and then try to create such a short clip at inference time, then it will probably struggle)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Ul3pLEYGbQ"
      },
      "source": [
        "### Clean the Dataset\n",
        "\n",
        "Now we will apply some filters to remove items from our dataset that are likely to be problematic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:59.539661Z",
          "iopub.status.busy": "2024-04-22T15:37:59.539092Z",
          "iopub.status.idle": "2024-04-22T15:37:59.581778Z",
          "shell.execute_reply": "2024-04-22T15:37:59.580276Z",
          "shell.execute_reply.started": "2024-04-22T15:37:59.539615Z"
        },
        "id": "Weh6vQfhYGbQ",
        "outputId": "3ab98e11-fe1f-4aee-cdf4-46f8396d317f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cleaned_data=[]\n",
        "len(data), len(cleaned_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:59.584495Z",
          "iopub.status.busy": "2024-04-22T15:37:59.583959Z",
          "iopub.status.idle": "2024-04-22T15:37:59.602214Z",
          "shell.execute_reply": "2024-04-22T15:37:59.600925Z",
          "shell.execute_reply.started": "2024-04-22T15:37:59.584453Z"
        },
        "id": "l7FG1tUJYGbQ",
        "outputId": "70fdc743-f7e2-43b5-a159-a69f3a09f800",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#first find our per char duration mean/sd\n",
        "durs_per_char = []\n",
        "for each in data:\n",
        "    durs_per_char.append(each[-1]/each[2])\n",
        "durs_mean = np.mean(durs_per_char)\n",
        "durs_sd = np.std(durs_per_char)\n",
        "\n",
        "durs_mean, durs_sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:37:59.603835Z",
          "iopub.status.busy": "2024-04-22T15:37:59.603506Z",
          "iopub.status.idle": "2024-04-22T15:38:00.136532Z",
          "shell.execute_reply": "2024-04-22T15:38:00.135223Z",
          "shell.execute_reply.started": "2024-04-22T15:37:59.603808Z"
        },
        "id": "aodmSDdwYGbQ",
        "outputId": "1d52173d-3dff-40f1-8646-0af336f14447",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "points = durs_per_char\n",
        "mean = durs_mean\n",
        "std_dev = durs_sd\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.hist(points, bins=30, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "# Add vertical lines for mean and standard deviation\n",
        "plt.axvline(mean, color='white', linestyle='dashed', linewidth=1.5, label=f'Mean: {mean:.5f}')\n",
        "plt.axvline(mean + std_dev, color='orange', linestyle='dashed', linewidth=1.5, label=f'Standard Deviation: {std_dev:.5f}')\n",
        "plt.axvline(mean - std_dev, color='orange', linestyle='dashed', linewidth=1.5)\n",
        "plt.axvline(mean + 2*std_dev, color='red', linestyle='dashed', linewidth=1.5, label=f'Standard Deviation: {std_dev:.5f}')\n",
        "plt.axvline(mean - 2*std_dev, color='red', linestyle='dashed', linewidth=1.5)\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Speech Duration Per Character for All Items')\n",
        "\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1jnP3bHYGbQ"
      },
      "source": [
        "We have found the mean duration per character of text and the above histogram shows how our dataset is distributed around that mean.\n",
        "\n",
        "Next we will filter out items with too short duration, items with too long duration, and items with too much variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.139899Z",
          "iopub.status.busy": "2024-04-22T15:38:00.13875Z",
          "iopub.status.idle": "2024-04-22T15:38:00.145833Z",
          "shell.execute_reply": "2024-04-22T15:38:00.144555Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.139852Z"
        },
        "id": "E2ZxkUqRYGbQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "minimum_duration = 0.7\n",
        "maximum_duration = 13.0\n",
        "maximum_sds = 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.14875Z",
          "iopub.status.busy": "2024-04-22T15:38:00.14822Z",
          "iopub.status.idle": "2024-04-22T15:38:00.196271Z",
          "shell.execute_reply": "2024-04-22T15:38:00.194138Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.148708Z"
        },
        "id": "SnCCD-vHYGbQ",
        "outputId": "a1c794fe-1a23-4576-d251-19938db062ff",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#TODO: add separate filter for removing items whose char length is > 250\n",
        "\n",
        "cleaned_data = []\n",
        "\n",
        "shorties = []\n",
        "longies = []\n",
        "misfits = []\n",
        "for item in data:\n",
        "    item_perchar_dur = item[-1]/item[2]\n",
        "    difference = abs(item_perchar_dur-durs_mean)\n",
        "    item_zscore = difference / durs_sd\n",
        "    item = item + (item_zscore,) #add the zscore to the data item so we can sort by it later\n",
        "    if item[-2] < minimum_duration:\n",
        "        shorties.append(item)\n",
        "    elif item[-2] > maximum_duration:\n",
        "        longies.append(item)\n",
        "    elif item_zscore > maximum_sds:\n",
        "        misfits.append(item)\n",
        "    else:\n",
        "        cleaned_data.append(item)\n",
        "\n",
        "excluded = shorties + longies + misfits\n",
        "\n",
        "\n",
        "print(f\"found {len(shorties)} short items and {len(longies)} long items and {len(misfits)} items whose length conformed but whose per-char duration exceeded {maximum_sds} standard deviations from the mean. Excluding {len(shorties)+len(longies)+len(misfits)} items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyD7CXdQYGbQ"
      },
      "source": [
        "Look at the items we are deeming too short to see if it looks sensible to exclude them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.198618Z",
          "iopub.status.busy": "2024-04-22T15:38:00.197923Z",
          "iopub.status.idle": "2024-04-22T15:38:00.206563Z",
          "shell.execute_reply": "2024-04-22T15:38:00.205197Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.198579Z"
        },
        "id": "V4-qg7wLYGbQ",
        "outputId": "605fecae-fb3b-4d7a-e95a-98a50025f24a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ranked_shorts = sorted(shorties, key=lambda x: x[-2])\n",
        "if len(ranked_shorts) > 0:\n",
        "    print(f\"Duration of shortest item excluded for being too short: {ranked_shorts[0][-2]} Text from shortest item excluded for being too short: {ranked_shorts[0][1]}\")\n",
        "    print(ranked_shorts[0])\n",
        "    print(f\"Duration of longest item excluded for being too short: {ranked_shorts[-1][-2]} Text from shortest item excluded for being too short: {ranked_shorts[-1][1]}\")\n",
        "    print(ranked_shorts[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLC0h4stYGbR"
      },
      "source": [
        "Likewise for the items with high variance (you might want to play around with the maximum_sds value above to find the right level of exclusion)\n",
        "\n",
        "(If you are following along in the janeeyre dataset, this actually picks up some items from the dataset that were mislabelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.208101Z",
          "iopub.status.busy": "2024-04-22T15:38:00.207734Z",
          "iopub.status.idle": "2024-04-22T15:38:00.406547Z",
          "shell.execute_reply": "2024-04-22T15:38:00.405037Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.20807Z"
        },
        "id": "jERQWUhBYGbR",
        "outputId": "d7e589f0-6f10-4a2e-d8bb-6ab4ee11fdf9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ranked_misfits = sorted(misfits, key=lambda x: x[-1])[::-1]\n",
        "if len(ranked_misfits) > 0:\n",
        "    print(f\"Duration of worst item excluded for having too much variance: {ranked_misfits[0][-2]} and its text: {ranked_misfits[0][1]}\")\n",
        "    print(ranked_misfits[0])\n",
        "    print(f\"Duration of best item excluded for having too much variance: {ranked_misfits[-1][-2]} and its text: {ranked_misfits[-1][1]}\")\n",
        "    print(ranked_misfits[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6SnHaY7YGbR"
      },
      "source": [
        "The following code is copy pasted from above--we are recomputing on our cleaned dataset to inspect it and compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.408919Z",
          "iopub.status.busy": "2024-04-22T15:38:00.408355Z",
          "iopub.status.idle": "2024-04-22T15:38:00.454898Z",
          "shell.execute_reply": "2024-04-22T15:38:00.45361Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.408885Z"
        },
        "id": "-maBQargYGbR",
        "outputId": "4a91e78a-313d-452d-9541-b61f04a661eb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "text_vs_durs = {}  # text length vs audio duration\n",
        "text_len_counter = Counter()  # number of sentences with the keyed length\n",
        "lengths = []\n",
        "for item in tqdm(cleaned_data):\n",
        "    text = item[1].lower().strip()\n",
        "    text_len = len(text)\n",
        "    text_len_counter[text_len] += 1\n",
        "    lengths.append(text_len)\n",
        "    audio_len = item[-2]\n",
        "    try:\n",
        "        text_vs_durs[text_len] += [audio_len]\n",
        "    except:\n",
        "        text_vs_durs[text_len] = [audio_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.456956Z",
          "iopub.status.busy": "2024-04-22T15:38:00.456562Z",
          "iopub.status.idle": "2024-04-22T15:38:00.489132Z",
          "shell.execute_reply": "2024-04-22T15:38:00.487828Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.456922Z"
        },
        "id": "vLU6AOy-YGbR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# text_len vs avg_audio_len, median_audio_len, std_audio_len\n",
        "text_vs_avg = {}\n",
        "text_vs_median = {}\n",
        "text_vs_std = {}\n",
        "for key, durs in text_vs_durs.items():\n",
        "    text_vs_avg[key] = np.mean(durs)\n",
        "    text_vs_median[key] = np.median(durs)\n",
        "    text_vs_std[key] = np.std(durs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.494043Z",
          "iopub.status.busy": "2024-04-22T15:38:00.493636Z",
          "iopub.status.idle": "2024-04-22T15:38:00.508448Z",
          "shell.execute_reply": "2024-04-22T15:38:00.507249Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.49401Z"
        },
        "id": "dFUyRK7fYGbR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sec_per_chars = []\n",
        "for item in cleaned_data:\n",
        "    text = item[1]\n",
        "    dur = item[-2]\n",
        "    sec_per_char = dur / len(text)\n",
        "    sec_per_chars.append(sec_per_char)\n",
        "# sec_per_char /= len(cleaned_data)\n",
        "# print(sec_per_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.510342Z",
          "iopub.status.busy": "2024-04-22T15:38:00.509999Z",
          "iopub.status.idle": "2024-04-22T15:38:00.52163Z",
          "shell.execute_reply": "2024-04-22T15:38:00.520371Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.510313Z"
        },
        "id": "el0XRZgbYGbV",
        "outputId": "72f256b8-e104-479f-d1c5-9a90e36fbcd3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mean = np.mean(sec_per_chars)\n",
        "std = np.std(sec_per_chars)\n",
        "print(mean)\n",
        "print(std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxO7seTJYGbV"
      },
      "source": [
        "We should see less outliers in the visualisations below and a tighter distribution of audio duration per char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.524019Z",
          "iopub.status.busy": "2024-04-22T15:38:00.523547Z",
          "iopub.status.idle": "2024-04-22T15:38:00.872971Z",
          "shell.execute_reply": "2024-04-22T15:38:00.871675Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.523968Z"
        },
        "id": "PVi-IUL_YGbV",
        "outputId": "c8a2126e-2a82-4103-8571-ac3d724804dc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.title(\"text length vs mean audio duration\")\n",
        "plt.scatter(list(text_vs_avg.keys()), list(text_vs_avg.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:00.875074Z",
          "iopub.status.busy": "2024-04-22T15:38:00.874549Z",
          "iopub.status.idle": "2024-04-22T15:38:01.228276Z",
          "shell.execute_reply": "2024-04-22T15:38:01.22691Z",
          "shell.execute_reply.started": "2024-04-22T15:38:00.874969Z"
        },
        "id": "oJbbJoKfYGbV",
        "outputId": "3395288a-6fbd-474f-b84a-18b0394fd2b1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.title(\"text length vs median audio duration\")\n",
        "plt.scatter(list(text_vs_median.keys()), list(text_vs_median.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:01.230528Z",
          "iopub.status.busy": "2024-04-22T15:38:01.23008Z",
          "iopub.status.idle": "2024-04-22T15:38:01.585275Z",
          "shell.execute_reply": "2024-04-22T15:38:01.584146Z",
          "shell.execute_reply.started": "2024-04-22T15:38:01.230492Z"
        },
        "id": "G620Ub1DYGbV",
        "outputId": "66a3f5ab-b814-4424-da6c-16c3a36c9524",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.title(\"text length vs STD\")\n",
        "plt.scatter(list(text_vs_std.keys()), list(text_vs_std.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:01.587908Z",
          "iopub.status.busy": "2024-04-22T15:38:01.587441Z",
          "iopub.status.idle": "2024-04-22T15:38:01.96433Z",
          "shell.execute_reply": "2024-04-22T15:38:01.963025Z",
          "shell.execute_reply.started": "2024-04-22T15:38:01.587864Z"
        },
        "id": "xQIH7noHYGbV",
        "outputId": "9399bc53-0982-4abf-c10f-a24441be4f39",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.hist(lengths, bins=20, edgecolor='black')  # Adjust the number of bins as needed\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Text Lengths in TTS Dataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:01.969794Z",
          "iopub.status.busy": "2024-04-22T15:38:01.968449Z",
          "iopub.status.idle": "2024-04-22T15:38:01.984928Z",
          "shell.execute_reply": "2024-04-22T15:38:01.983519Z",
          "shell.execute_reply.started": "2024-04-22T15:38:01.969741Z"
        },
        "id": "fLZoixY4YGbV",
        "outputId": "df2be95f-a8e2-47e6-e1b3-def5f28da82b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#after cleaning distribution\n",
        "#first find our per char duration mean/sd\n",
        "durs_per_char = []\n",
        "for each in cleaned_data:\n",
        "    durs_per_char.append(each[-2]/each[2])\n",
        "durs_mean = np.mean(durs_per_char)\n",
        "durs_sd = np.std(durs_per_char)\n",
        "\n",
        "durs_mean, durs_sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:38:01.986947Z",
          "iopub.status.busy": "2024-04-22T15:38:01.986538Z",
          "iopub.status.idle": "2024-04-22T15:38:02.509887Z",
          "shell.execute_reply": "2024-04-22T15:38:02.508537Z",
          "shell.execute_reply.started": "2024-04-22T15:38:01.986912Z"
        },
        "id": "QRiGsNlTYGbV",
        "outputId": "bdfc0a8d-4c73-4969-af28-fe31a53edd09",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "points = durs_per_char\n",
        "mean = durs_mean\n",
        "std_dev = durs_sd\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.hist(points, bins=30, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "# Add vertical lines for mean and standard deviation\n",
        "plt.axvline(mean, color='white', linestyle='dashed', linewidth=1.5, label=f'Mean: {mean:.5f}')\n",
        "plt.axvline(mean + std_dev, color='orange', linestyle='dashed', linewidth=1.5, label=f'Standard Deviation: {std_dev:.5f}')\n",
        "plt.axvline(mean - std_dev, color='orange', linestyle='dashed', linewidth=1.5)\n",
        "plt.axvline(mean + 2*std_dev, color='red', linestyle='dashed', linewidth=1.5, label=f'Standard Deviation: {std_dev:.5f}')\n",
        "plt.axvline(mean - 2*std_dev, color='red', linestyle='dashed', linewidth=1.5)\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Speech Duration Per Character for All Items')\n",
        "\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdBdz5IJYGbV"
      },
      "source": [
        "### Visualise Cull\n",
        "\n",
        "Check how much content we are proposing to remove from our dataset. I don't know how much data is 'enough' to train on. In my experience, 2 hours is plenty of audio duration (I trained a model on 10 hours of audio and a 2 hour subset of that data and I couldn't notice much difference between the two). The more high quality content, the better.\n",
        "\n",
        "If you are having to cut a large amount of data at this stage, then your dataset probably isn't being created correctly to begin with. [here](https://github.com/zuverschenken/XTTSv2Scripts) is my repo showing how to create a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:40:29.34804Z",
          "iopub.status.busy": "2024-04-22T15:40:29.347564Z",
          "iopub.status.idle": "2024-04-22T15:40:29.357163Z",
          "shell.execute_reply": "2024-04-22T15:40:29.355515Z",
          "shell.execute_reply.started": "2024-04-22T15:40:29.348006Z"
        },
        "id": "8IfPGNXsYGbW",
        "outputId": "e073eac7-bf83-4299-f998-6592b6bf1914",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "len(excluded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:40:30.130778Z",
          "iopub.status.busy": "2024-04-22T15:40:30.130336Z",
          "iopub.status.idle": "2024-04-22T15:40:30.139303Z",
          "shell.execute_reply": "2024-04-22T15:40:30.138251Z",
          "shell.execute_reply.started": "2024-04-22T15:40:30.130746Z"
        },
        "id": "NgTuY5nUYGbW",
        "outputId": "164b1f82-8b7e-47f6-b081-ec2887d82d9a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "len(data), len(cleaned_data), len(cleaned_data)/len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:40:36.652114Z",
          "iopub.status.busy": "2024-04-22T15:40:36.651674Z",
          "iopub.status.idle": "2024-04-22T15:40:36.662073Z",
          "shell.execute_reply": "2024-04-22T15:40:36.660891Z",
          "shell.execute_reply.started": "2024-04-22T15:40:36.652081Z"
        },
        "id": "PslzkRB2YGbW",
        "outputId": "246ea422-9426-445b-ec1e-775fa9424f8f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "remaining_length = sum([each[-2] for each in cleaned_data])\n",
        "excluded_length = sum([each[-2] for each in excluded])\n",
        "remaining_length, excluded_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:40:40.977914Z",
          "iopub.status.busy": "2024-04-22T15:40:40.977504Z",
          "iopub.status.idle": "2024-04-22T15:40:41.171528Z",
          "shell.execute_reply": "2024-04-22T15:40:41.169717Z",
          "shell.execute_reply.started": "2024-04-22T15:40:40.977883Z"
        },
        "id": "xvNfamniYGbW",
        "outputId": "a59318d7-870e-4ea3-d8b4-75d39836696b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Data for the pie chart (proportions)\n",
        "sizes = [remaining_length, excluded_length]  # Example proportions, summing up to 100%\n",
        "\n",
        "# Labels for each portion\n",
        "labels = ['Remaining Data', 'Excluded Data']\n",
        "\n",
        "# Colors for each portion\n",
        "colors = ['lightblue', 'lightcoral']  # Adjusted color for 'lightred'\n",
        "\n",
        "# Create pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.title('Proportion of seconds of audio kept after cull')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:41:06.243308Z",
          "iopub.status.busy": "2024-04-22T15:41:06.242871Z",
          "iopub.status.idle": "2024-04-22T15:41:06.251073Z",
          "shell.execute_reply": "2024-04-22T15:41:06.249777Z",
          "shell.execute_reply.started": "2024-04-22T15:41:06.243274Z"
        },
        "id": "ShQ9bSbiYGbW",
        "outputId": "52f15f3f-6406-4730-967f-f7ee690d7f66",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def seconds_to_hms(seconds):\n",
        "    hours = seconds // 3600\n",
        "    minutes = (seconds % 3600) // 60\n",
        "    remaining_seconds = seconds % 60\n",
        "    return hours, minutes, remaining_seconds\n",
        "\n",
        "hours, minutes, remaining_seconds = seconds_to_hms(remaining_length)\n",
        "print(f\"Remaining length: {hours} hours, {minutes} minutes, and {remaining_seconds} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:41:09.741031Z",
          "iopub.status.busy": "2024-04-22T15:41:09.740363Z",
          "iopub.status.idle": "2024-04-22T15:41:09.747331Z",
          "shell.execute_reply": "2024-04-22T15:41:09.745983Z",
          "shell.execute_reply.started": "2024-04-22T15:41:09.740996Z"
        },
        "id": "adCufsDTYGbW",
        "outputId": "f5e350f8-b158-4a8e-d64c-9832b6924934",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "hours, minutes, remaining_seconds = seconds_to_hms(excluded_length)\n",
        "print(f\"Excluded length: {hours} hours, {minutes} minutes, and {remaining_seconds} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ThFAM-CYGbW"
      },
      "source": [
        "### Check Parameter for Fine-tune\n",
        "\n",
        "If you are using this data with XTTS-v2, you should use the maximum audio length from your dataset as max_wav_length and ensure the length of the reference audio you want to use is within the min-max range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:51:09.33224Z",
          "iopub.status.busy": "2024-04-22T15:51:09.330317Z",
          "iopub.status.idle": "2024-04-22T15:51:09.478877Z",
          "shell.execute_reply": "2024-04-22T15:51:09.477644Z",
          "shell.execute_reply.started": "2024-04-22T15:51:09.332178Z"
        },
        "id": "E6Fwu4ovYGbW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "speaker_reference = '/input/trmp/trumpbagdaddy.wav'\n",
        "audio, sr = librosa.load(os.path.join(training_dir, 'wavs', speaker_reference), sr=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:51:37.507708Z",
          "iopub.status.busy": "2024-04-22T15:51:37.507213Z",
          "iopub.status.idle": "2024-04-22T15:51:37.52084Z",
          "shell.execute_reply": "2024-04-22T15:51:37.519053Z",
          "shell.execute_reply.started": "2024-04-22T15:51:37.507671Z"
        },
        "id": "89tmKBMIYGbW",
        "outputId": "8ab958a5-02eb-4814-e285-5350408f810d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "rawLength = [x[-2] for x in cleaned_data]\n",
        "\n",
        "print(f\"seconds: {max(rawLength)}\")\n",
        "print(f\"maximum audio file length: {max(rawLength)*sr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:54:00.049Z",
          "iopub.status.busy": "2024-04-22T15:54:00.047703Z",
          "iopub.status.idle": "2024-04-22T15:54:00.058879Z",
          "shell.execute_reply": "2024-04-22T15:54:00.056609Z",
          "shell.execute_reply.started": "2024-04-22T15:54:00.048826Z"
        },
        "id": "Z1on6coxYGbX",
        "outputId": "0f69f7c0-456b-48ad-bd63-84afe0988928",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f\"speaker reference file length: {len(audio)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## No need to continue past this point with the example dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvuklZwOYGbX"
      },
      "source": [
        "### Delete Unwanted Files.\n",
        "\n",
        "Finally we copy across the files we want to keep to /kaggle/working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:55:14.04474Z",
          "iopub.status.busy": "2024-04-22T15:55:14.043245Z",
          "iopub.status.idle": "2024-04-22T15:55:14.049697Z",
          "shell.execute_reply": "2024-04-22T15:55:14.048655Z",
          "shell.execute_reply.started": "2024-04-22T15:55:14.044683Z"
        },
        "id": "C0kKn4j0YGbX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "out_dir = '/workspace/output/' # choose an output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:55:19.238474Z",
          "iopub.status.busy": "2024-04-22T15:55:19.237977Z",
          "iopub.status.idle": "2024-04-22T15:55:19.246508Z",
          "shell.execute_reply": "2024-04-22T15:55:19.245037Z",
          "shell.execute_reply.started": "2024-04-22T15:55:19.238426Z"
        },
        "id": "JYIfYCGWYGbX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "excluded_files = set([each[0].split('/')[-1].split('.')[0] for each in excluded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:55:28.472457Z",
          "iopub.status.busy": "2024-04-22T15:55:28.472025Z",
          "iopub.status.idle": "2024-04-22T15:55:28.527929Z",
          "shell.execute_reply": "2024-04-22T15:55:28.526592Z",
          "shell.execute_reply.started": "2024-04-22T15:55:28.472423Z"
        },
        "id": "AaXH7HtOYGbX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#grab the rows we will keep\n",
        "dropped = 0\n",
        "sanitised_rows = []\n",
        "with open(os.path.join(training_dir, 'metadata.csv'), 'r') as file:\n",
        "    csv_reader = csv.reader(file, delimiter='|')\n",
        "    for row in csv_reader:\n",
        "        if row[0] not in excluded_files:\n",
        "            sanitised_rows.append(row)\n",
        "        else:\n",
        "            dropped += 1\n",
        "\n",
        "#sanity check\n",
        "assert dropped == len(excluded_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:55:30.789619Z",
          "iopub.status.busy": "2024-04-22T15:55:30.789117Z",
          "iopub.status.idle": "2024-04-22T15:55:30.923929Z",
          "shell.execute_reply": "2024-04-22T15:55:30.922555Z",
          "shell.execute_reply.started": "2024-04-22T15:55:30.789582Z"
        },
        "id": "NaekET6bYGbX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#create a new csv\n",
        "with open(os.path.join(out_dir, 'metadata.csv'), 'w', encoding='utf-8') as file:\n",
        "    csv_writer = csv.writer(file, delimiter = '|')\n",
        "    for row in sanitised_rows:\n",
        "        csv_writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmtBFYzYGbX"
      },
      "source": [
        "**Note: copying all wavs to working dir. This might take some time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T15:55:36.883722Z",
          "iopub.status.busy": "2024-04-22T15:55:36.883285Z",
          "iopub.status.idle": "2024-04-22T15:56:09.832136Z",
          "shell.execute_reply": "2024-04-22T15:56:09.830831Z",
          "shell.execute_reply.started": "2024-04-22T15:55:36.883689Z"
        },
        "id": "itS5NcCBYGbX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "wavs_dir = os.path.join(out_dir, 'wavs')\n",
        "os.makedirs(wavs_dir, exist_ok=True)\n",
        "\n",
        "files = os.listdir(os.path.join(training_dir, 'wavs'))\n",
        "\n",
        "for file in files:\n",
        "    source_file = os.path.join(training_dir,'wavs', file)\n",
        "    destination_file = os.path.join(wavs_dir, file)\n",
        "    shutil.copy2(source_file, destination_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GvVPh85YGbY"
      },
      "source": [
        "Delete the unwanted wavs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:56:50.913209Z",
          "iopub.status.busy": "2024-04-22T15:56:50.912723Z",
          "iopub.status.idle": "2024-04-22T15:56:50.952356Z",
          "shell.execute_reply": "2024-04-22T15:56:50.950476Z",
          "shell.execute_reply.started": "2024-04-22T15:56:50.913177Z"
        },
        "id": "C06Qz8iaYGbY",
        "outputId": "db7102e1-f546-4dee-c8cd-14ad9606ff3e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#delete wavs\n",
        "deleted_files = 0\n",
        "for file_name in excluded_files:\n",
        "    file_path = os.path.join(wavs_dir, file_name + '.wav')\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "        deleted_files += 1\n",
        "    except OSError as e:\n",
        "        print(f'Error deleting file {file_path}: {e}')\n",
        "\n",
        "#sanity check\n",
        "assert deleted_files == dropped\n",
        "print(f'deleted {deleted_files} wavs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBPqKFffYGbY"
      },
      "source": [
        "Create a tarball that you can download. Again, this might take a little while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-22T15:57:45.611315Z",
          "iopub.status.busy": "2024-04-22T15:57:45.61089Z",
          "iopub.status.idle": "2024-04-22T15:59:50.216549Z",
          "shell.execute_reply": "2024-04-22T15:59:50.214817Z",
          "shell.execute_reply.started": "2024-04-22T15:57:45.611282Z"
        },
        "id": "NkuS9ADsYGbY",
        "outputId": "71ac5b08-0519-4faf-80ad-a44f8116907e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!tar -czvf culled_dataset.tar.gz /workspace/output/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eotl4i0aYGbY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Inspect and Clean TTS Dataset",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4372173,
          "sourceId": 7507317,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
